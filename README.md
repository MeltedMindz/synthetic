# SYNTHETIC-LIFE-PHI

A Unity ML-Agents simulation of synthetic lifeforms trained with PPO + LSTM to survive, grow, age, and reproduce under homeostatic constraints, while sensing a hidden global field Φ(x,t) generated by Perlin-noise "waves".

## Overview

This project simulates creatures that:
- Maintain homeostasis (Energy, Temperature, Integrity)
- Grow through life stages (Juvenile → Adult → Elder)
- Reproduce with heritable traits and mutations
- Sense a hidden Φ field using antenna-like sensors
- Use an epistemic "Scan" action to improve information quality
- Navigate temperature zones, hazards, and food sources

**Note on Measurement Back-Action**: The optional "back-action" toggle is a pure game mechanic that temporarily disturbs the local Φ field upon scanning. This is not a quantum mechanical claim—it's a simulation mechanic to add strategic depth to information gathering.

## Requirements

- **Unity**: 2022.3 LTS (2022.3.22f1 or compatible)
- **ML-Agents**: 2.0.1 (included via Package Manager)
- **Python**: 3.8+ (for ML-Agents training)
- **mlagents**: Latest stable (via pip)

## Installation

### 1. Install Unity 2022.3 LTS

1. Download Unity Hub: https://unity.com/download
2. Install Unity 2022.3.22f1 LTS via Unity Hub
3. Ensure "Windows Build Support" (or Mac/Linux equivalent) is installed

### 2. Clone and Open Project

```bash
git clone <repository-url>
cd synthetic
```

Open Unity Hub → Add → Select the `synthetic` folder

### 3. Install ML-Agents Python Package

```bash
# Create a virtual environment (recommended)
python -m venv mlagents-env

# Activate it
# On Windows:
mlagents-env\Scripts\activate
# On macOS/Linux:
source mlagents-env/bin/activate

# Install ML-Agents (matching Unity package version)
pip install -U pip
pip install mlagents
```

**Note:** The Unity package uses ML-Agents 2.0.1. The Python package version should be compatible (latest stable works).

### 4. Verify Unity Project Setup

1. Open Unity and wait for packages to resolve
2. ML-Agents should appear in Package Manager (Window → Package Manager)
3. Ensure no compilation errors in Console

## Project Structure

```
synthetic/
├── Assets/
│   ├── Scripts/
│   │   ├── Core/
│   │   │   ├── CreatureAgent.cs        # Main ML-Agents agent
│   │   │   ├── GrowthSystem.cs         # Age, stages, size logic
│   │   │   ├── Genome.cs               # Heritable traits
│   │   │   └── PopulationManager.cs    # Population control
│   │   ├── World/
│   │   │   ├── PhiField.cs            # Perlin noise Φ field
│   │   │   ├── FoodSpawner.cs         # Food spawning system
│   │   │   ├── FoodItem.cs            # Individual food objects
│   │   │   ├── TemperatureZone.cs     # Temperature regions
│   │   │   ├── HazardZone.cs          # Damage zones
│   │   │   └── ShelterZone.cs         # Safe rest zones
│   │   ├── Config/
│   │   │   ├── CreatureDefaults.cs    # Creature config SO
│   │   │   ├── PhiFieldConfig.cs      # Φ field config SO
│   │   │   ├── SpawnerConfig.cs       # Food spawner config SO
│   │   │   └── RewardConfig.cs        # Reward tuning SO
│   │   └── Utils/
│   │       ├── MetricsLogger.cs       # CSV metrics logging
│   │       └── DebugUI.cs             # On-screen stats
│   └── Scenes/
│       └── TrainingArena.unity        # Training scene
├── Config/
│   ├── ppo_life_v1.yaml              # Baseline PPO config
│   └── ppo_life_curriculum.yaml      # Curriculum learning config
└── README.md
```

## Scene Setup Instructions

### Creating the Training Arena Scene

1. **Create New Scene**: File → New Scene → Basic (Built-in)

2. **Setup Ground Plane**:
   - Create → 3D Object → Plane
   - Scale to (5, 1, 5) for 50x50 arena
   - Name: "Arena"

3. **Add PhiField**:
   - Create → Create Empty → Name: "PhiField"
   - Add Component: `PhiField` script
   - Create a ScriptableObject: Assets → Create → SyntheticLife/Config/PhiFieldConfig
   - Assign config to PhiField component

4. **Add Food Spawner**:
   - Create → Create Empty → Name: "FoodSpawner"
   - Add Component: `FoodSpawner` script
   - Create ScriptableObject: Assets → Create → SyntheticLife/Config/SpawnerConfig
   - Create a food prefab: Cube scaled to (0.5, 0.5, 0.5), add `FoodItem` script
   - Assign prefab and config to FoodSpawner

5. **Add Temperature Zones**:
   - Create → 3D Object → Cube → Name: "HotZone"
   - Scale to (10, 0.1, 10), position away from center
   - Add Component: `TemperatureZone`, set temperatureValue = 0.8
   - Repeat for "ColdZone" with temperatureValue = 0.2
   - Set tags to "TemperatureZone"

6. **Add Hazards**:
   - Create → 3D Object → Cube → Name: "HazardZone1"
   - Scale to (5, 0.1, 5), position in arena
   - Add Component: `HazardZone`, set damagePerSecond = 0.1
   - Set tag to "Hazard"
   - Duplicate as needed

7. **Add Shelter**:
   - Create → 3D Object → Cube → Name: "Shelter"
   - Scale to (8, 2, 8), position in arena
   - Add Component: `ShelterZone`
   - Set tag to "Shelter"
   - Make it green/marked visually

8. **Create Creature Prefab**:
   - Create → 3D Object → Capsule → Name: "Creature"
   - Add Component: `Rigidbody` (freeze Y rotation)
   - Add Component: `CreatureAgent`
   - Add Component: `GrowthSystem`
   - Add Component: `RayPerceptionSensorComponent3D`
     - Configure ray sensors:
       - Rays Per Direction: 12
       - Max Ray Degrees: 90
       - Ray Length: 10
       - Detectable Tags: Food, Hazard, Shelter, Creature
   - Add Component: `Behavior Parameters`
     - Behavior Name: "Creature"
     - Vector Observation:
       - Space Size: 17 (energy, temp, integrity, age, size, stage(3), phi(1), phiGradient(2), velocity(2), heading(2), cooldown, shelter)
       - Stacked Vectors: 1
     - Actions:
       - Continuous Actions: 2 (move forward, turn)
       - Discrete Branch Size: [2, 2] (scan, reproduce)

   - Create ScriptableObjects:
     - Assets → Create → SyntheticLife/Config/CreatureDefaults
     - Assets → Create → SyntheticLife/Config/RewardConfig
     - Assign to CreatureAgent component

   - Drag to Project to create prefab

9. **Add Population Manager**:
   - Create → Create Empty → Name: "PopulationManager"
   - Add Component: `PopulationManager`
   - Assign creature prefab

10. **Add Metrics Logger (Optional)**:
    - Create → Create Empty → Name: "MetricsLogger"
    - Add Component: `MetricsLogger`

11. **Add Debug UI (Optional)**:
    - Canvas → UI → Text
    - Add Component: `DebugUI`
    - Assign text component

12. **Create Walls (Optional)**:
    - Add invisible walls or kill zones to keep agents in bounds

13. **Save Scene**: Save as `Assets/Scenes/TrainingArena.unity`

### Tag Setup

Ensure these tags exist (should be auto-created):
- Food
- Hazard
- Shelter
- Creature
- TemperatureZone

Go to: Edit → Project Settings → Tags and Layers

## Training

### 1. Start Training Server

**In a terminal:**

```bash
# Navigate to project root
cd /path/to/synthetic

# Activate your Python environment
source mlagents-env/bin/activate  # macOS/Linux
# or
mlagents-env\Scripts\activate      # Windows

# Start training server (leave this running)
mlagents-learn Config/ppo_life_v1.yaml --run-id life_v1 --train
```

The server will wait for Unity to connect on port 5004.

### 2. Press Play in Unity

- In Unity Editor, press **▶️ Play**
- Unity will connect to the Python trainer automatically
- Console message will change from "inference mode" to "Connected to trainer on port 5004"
- Training will begin automatically

### 3. Monitor Training

- **Terminal**: Shows training progress, episode stats, rewards
- **Unity Console**: Shows connection status, episode events
- **TensorBoard**: `tensorboard --logdir results` (in another terminal)

### 3. Monitor Training

- TensorBoard: `tensorboard --logdir results`
- Unity Console: Episode counts, rewards
- Metrics CSV: `Application.persistentDataPath/metrics.csv`

### 4. Stop Training

- Press Play again in Unity to stop
- Ctrl+C in terminal to stop Python trainer

## Inference (Running Trained Model)

1. **Train a model** (see above) until you see `.onnx` files in `results/`

2. **Load model in Unity**:
   - Select Creature prefab
   - In Behavior Parameters component:
     - Model: Drag the `.onnx` file
     - Inference Device: CPU (or GPU if available)
     - Behavior Type: Inference Only

3. **Press Play**: Agent will use trained policy

## Configuration

### Toggle Back-Action

- Select PhiField object in scene
- In Inspector, check/uncheck `enableBackAction` in PhiFieldConfig

### Toggle Visualization

- Select PhiField object
- Check `showVisualization` in PhiFieldConfig
- View Gizmos in Scene view (Gizmos toggle)

### Adjust Rewards

- Edit `RewardConfig` ScriptableObject
- Values are tuned to prevent reward hacking
- Living reward only applies if healthy
- Reproduction rewards are delayed/survival-based

## Key Design Decisions

### Homeostasis System

- **Energy**: Drained by metabolism, movement, scanning. Gained from food.
- **Temperature**: Drifts toward ambient. Out-of-range causes integrity damage.
- **Integrity**: Damaged by hazards, temperature stress. Heals slowly in shelter.

### Growth & Aging

- Age increases continuously
- Stage transitions depend on age + nutrition/stress history
- Size scales with age and nutrition, affects all costs/capacities

### Reproduction

- Requires Adult stage, sufficient energy/integrity, cooldown
- Genome mutates with Gaussian noise
- Population manager enforces max creatures (removes oldest/lowest integrity)

### Φ Field

- Continuous Perlin noise field
- Affects food nutrient value (via `phiAffinity` trait)
- Agents sense noisy Φ values
- Scan action improves sensing quality

### Reward Design

- **Living reward**: Small positive only if healthy (prevents "stand still and die")
- **Food reward**: Diminishing returns
- **Reproduction reward**: Small immediate, larger if offspring/parent survive
- **Death penalty**: Large negative
- **Exploration reward**: Novelty-based (optional)

This design avoids common reward hacking like "suicide to reproduce" by:
1. Living reward only when healthy
2. Reproduction costs significant energy
3. Offspring survival rewards are delayed
4. Death penalty is severe

## Troubleshooting

### ML-Agents Connection Issues

- Ensure Python environment has `mlagents` installed
- Check Unity Console for connection status
- Verify Behavior Name matches YAML config

### Missing References

- Ensure all ScriptableObjects are created and assigned
- Check prefab setup (components, tags, layers)
- Verify scene objects have required components

### Training Not Learning

- Check reward signals (TensorBoard)
- Adjust hyperparameters in YAML
- Verify observations include meaningful information
- Check that rewards are being given (Unity Console)

### Performance Issues

- Reduce max creatures in PopulationManager
- Lower ray perception ray count
- Reduce arena size

## Extending the Project

### Adding New Traits

1. Extend `Genome` struct in `Genome.cs`
2. Add mutation logic in `Genome.Mutate()`
3. Use trait in `CreatureAgent` or `GrowthSystem`

### Adding New Sensors

1. Add observation in `CreatureAgent.CollectObservations()`
2. Update Behavior Parameters Vector Observation Space Size

### Adding New Actions

1. Add action handling in `CreatureAgent.OnActionReceived()`
2. Update Behavior Parameters Discrete Branch Size

## License

[Your License Here]

## Credits

Built with Unity ML-Agents Toolkit.

